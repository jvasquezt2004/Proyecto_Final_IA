{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>BP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Na_to_K</th>\n",
       "      <th>Drug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>25.355</td>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>13.093</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>10.114</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>F</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>7.798</td>\n",
       "      <td>drugX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>F</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>18.043</td>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Sex      BP Cholesterol  Na_to_K   Drug\n",
       "0   23   F    HIGH        HIGH   25.355  drugY\n",
       "1   47   M     LOW        HIGH   13.093  drugC\n",
       "2   47   M     LOW        HIGH   10.114  drugC\n",
       "3   28   F  NORMAL        HIGH    7.798  drugX\n",
       "4   61   F     LOW        HIGH   18.043  drugY"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"../drug200.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "categorical_columns = categorical_columns.drop('Drug')\n",
    "data_encoded = pd.get_dummies(data, columns=categorical_columns, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "data_encoded['Drug'] = le.fit_transform(data['Drug'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_encoded.drop('Drug', axis=1)\n",
    "y = data_encoded['Drug']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Na_to_K', 'Drug', 'Sex_M', 'BP_LOW', 'BP_NORMAL',\n",
       "       'Cholesterol_NORMAL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_encoded.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arbol de decision\n",
    "Normalmente para un random forest se usan arboles de decision binarios comunes, que se construyen usando CART, en donde dividen recursivamente los subconjuntos basados en una caracteristica que minimiza las impurezas, en este caso se uso la impureza de Gini\n",
    "\n",
    "## Impureza de Gini (Funcion best_split)\n",
    "Mide la frecuencia con la que un elemento elegido de forma aleatoria seria categorizado de forma incorrecta si se etiqueara aleatoriamente segun la distribucion de etiquetas del subconjunto.\n",
    "\n",
    "## Muestreo aleatorio de caracteristicas\n",
    "En cada nodo se seleccina un subconjunto aleatorio de caracteristicas para considerar la division, introduciendo variabilidad y reduciendo la correlacion entre los arboles mejorando la generalizacion del modelo\n",
    "\n",
    "## Crecimiento completo (grow_tree)\n",
    "Los arboles crecen hasata su maxima profundidad posible, es decir hasta que todas las hojas tienen menos de una cierta cantidad de instancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_classes = len(np.unique(y))\n",
    "        self.n_features = X.shape[1]\n",
    "        self.tree = self._grow_tree(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict(inputs) for inputs in X])\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        n_samples, n_features = X.shape\n",
    "        if n_samples == 0 or depth == self.max_depth:\n",
    "            most_common_label = np.bincount(y).argmax()\n",
    "            return most_common_label\n",
    "        best_feat, best_thresh = self._best_split(X, y, n_features)\n",
    "        if best_feat is None:\n",
    "            most_common_label = np.bincount(y).argmax()\n",
    "            return most_common_label\n",
    "        left_idxs, right_idxs = self._split(X[:, best_feat], best_thresh)\n",
    "        left = self._grow_tree(X[left_idxs, :], y[left_idxs], depth + 1)\n",
    "        right = self._grow_tree(X[right_idxs, :], y[right_idxs], depth + 1)\n",
    "        return (best_feat, best_thresh, left, right)\n",
    "\n",
    "    def _best_split(self, X, y, n_features):\n",
    "        m, n = X.shape\n",
    "        if m <= 1:\n",
    "            return None, None\n",
    "        num_parent = [np.sum(y == c) for c in range(self.n_classes)]\n",
    "        best_gini = 1.0 - sum((num / m) ** 2 for num in num_parent)\n",
    "        best_feat, best_thresh = None, None\n",
    "        for feat in range(n_features):\n",
    "            thresholds, classes = zip(*sorted(zip(X[:, feat], y)))\n",
    "            num_left = [0] * self.n_classes\n",
    "            num_right = num_parent.copy()\n",
    "            for i in range(1, m):\n",
    "                c = classes[i - 1]\n",
    "                num_left[c] += 1\n",
    "                num_right[c] -= 1\n",
    "                gini_left = 1.0 - sum((num_left[x] / i) ** 2 for x in range(self.n_classes))\n",
    "                gini_right = 1.0 - sum((num_right[x] / (m - i)) ** 2 for x in range(self.n_classes))\n",
    "                gini = (i * gini_left + (m - i) * gini_right) / m\n",
    "                if thresholds[i] == thresholds[i - 1]:\n",
    "                    continue\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_feat = feat\n",
    "                    best_thresh = (thresholds[i] + thresholds[i - 1]) / 2\n",
    "        return best_feat, best_thresh\n",
    "\n",
    "    def _split(self, X_column, split_thresh):\n",
    "        left_idxs = np.argwhere(X_column <= split_thresh).flatten()\n",
    "        right_idxs = np.argwhere(X_column > split_thresh).flatten()\n",
    "        return left_idxs, right_idxs\n",
    "\n",
    "    def _predict(self, inputs):\n",
    "        node = self.tree\n",
    "        while isinstance(node, tuple):\n",
    "            if inputs[node[0]] <= node[1]:\n",
    "                node = node[2]\n",
    "            else:\n",
    "                node = node[3]\n",
    "        return node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcionamiento del random forest:\n",
    "El random forest se basa en la idea de ensamblar multiples arboles de decision, la idea siendo que se pueden combinar las predicciones de arios arboles para mejorar la precision y asi controlar el sobre ajuste\n",
    "\n",
    "## Bootsrap sampling (Funcion fit)\n",
    "Generacion de varios subconjuntos de datos a partir del original usando muestreo con reemplazo\n",
    "\n",
    "## Construccion de arboles (En la clase del arbol la funcion grow_tree)\n",
    "Para cada subconjunto se contruye un arbol de decision, en donde durante su construccion en cada nodo se selecciona un subconjunto aleatorio de caracteristicas en lugar de considerar todas las posibles\n",
    "\n",
    "## Prediccion\n",
    "Cuando ya se contruyen todos los arboles, el modelo hace predicciones basadas en el conjunto de arboles, para cada tarea el arbol elige una clase y la clase que mas fue elegida es la que se usa para el modelo, siendo la predicion final el promedio de las predicciones de todos los arboles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, n_trees=100, max_depth=None):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        for _ in range(self.n_trees):\n",
    "            idxs = np.random.choice(len(X), len(X), replace=True)\n",
    "            tree = DecisionTree(max_depth=self.max_depth)\n",
    "            tree.fit(X[idxs], y[idxs])\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        tree_preds = np.array([tree.predict(X) for tree in self.trees])\n",
    "        return mode(tree_preds, axis=0)[0].flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patient_data():\n",
    "    # Ingresar las características del paciente\n",
    "    age = int(input(\"Ingrese la edad del paciente: \"))\n",
    "    sex = input(\"Ingrese el sexo del paciente (F/M): \")\n",
    "    bp = input(\"Ingrese la presión sanguínea del paciente (HIGH/LOW/NORMAL): \")\n",
    "    cholesterol = input(\"Ingrese el nivel de colesterol del paciente (HIGH/NORMAL): \")\n",
    "    na_to_k = float(input(\"Ingrese la relación Na_to_K del paciente: \"))\n",
    "\n",
    "    # Crear un DataFrame con los datos ingresados\n",
    "    patient_data = pd.DataFrame({\n",
    "        'Age': [age],\n",
    "        'Sex': [sex],\n",
    "        'BP': [bp],\n",
    "        'Cholesterol': [cholesterol],\n",
    "        'Na_to_K': [na_to_k]\n",
    "    })\n",
    "\n",
    "    # Aplicar las mismas transformaciones que en los datos de entrenamiento\n",
    "    categorical_columns = patient_data.select_dtypes(include=['object']).columns\n",
    "    patient_data_encoded = pd.get_dummies(patient_data, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "    # Asegurarse de que las columnas del DataFrame del paciente coincidan con las del conjunto de entrenamiento\n",
    "    missing_cols = set(X_train.columns) - set(patient_data_encoded.columns)\n",
    "    for col in missing_cols:\n",
    "        patient_data_encoded[col] = 0\n",
    "    patient_data_encoded = patient_data_encoded[X_train.columns]\n",
    "\n",
    "    return patient_data_encoded.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForest(n_trees=10, max_depth=5)\n",
    "rf.fit(X_train.values, y_train.values)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred = rf.predict(X_test.values)\n",
    "\n",
    "# Evaluar el modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor medicamento para el paciente es: drugB\n"
     ]
    }
   ],
   "source": [
    "patient_data = get_patient_data()\n",
    "\n",
    "# Predecir el mejor medicamento para el paciente\n",
    "predicted_drug = rf.predict(patient_data)\n",
    "predicted_drug_label = le.inverse_transform(predicted_drug)[0]\n",
    "\n",
    "print(f'El mejor medicamento para el paciente es: {predicted_drug_label}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
