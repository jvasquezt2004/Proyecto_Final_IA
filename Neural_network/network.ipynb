{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>BP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Na_to_K</th>\n",
       "      <th>Drug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>25.355</td>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>13.093</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>10.114</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>F</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>7.798</td>\n",
       "      <td>drugX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>F</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>18.043</td>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Sex      BP Cholesterol  Na_to_K   Drug\n",
       "0   23   F    HIGH        HIGH   25.355  drugY\n",
       "1   47   M     LOW        HIGH   13.093  drugC\n",
       "2   47   M     LOW        HIGH   10.114  drugC\n",
       "3   28   F  NORMAL        HIGH    7.798  drugX\n",
       "4   61   F     LOW        HIGH   18.043  drugY"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"../drug200.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codificacoin de las variables categoricas\n",
    "Consiste en tomar todas las variables que son cualitativas y transformarlas a valores numericos con el fin de que sea mas facil a nivel matematico su procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoders = {}\n",
    "for column in [\"Sex\", \"BP\", \"Cholesterol\", \"Drug\"]:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separacion de caracteristicas\n",
    "Se dvide en dos ejes, el de x en donde estan los valores independientes de la funcion y y en donde esta la variable dependiente (En este caso Drug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(\"Drug\", axis=1).values\n",
    "y = data[\"Drug\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizacion\n",
    "Se normalizan con el fin de que la media sea cero y la desviacion estandar uno, esto permite que la red neuronal entrene de forma mas eficiente, ya que estas aprenden mejor cuando las entradas se encuentran en rangos similares, haciendo que las que tienen valores mas grandes no dominen el proceso de aprendizaje y de esa forma prestar atencion a todo los detalles por mas minimos que sean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Division de datos en conjuntos\n",
    "Se hace un conjunto de entrenamiento, que consiste en el 80% y uno de priebas que consiste en el 20%, es decir que el 80% de todo el dataset se usa para entrenar mientras que el otro 20 para realizar pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red neuronal\n",
    "Se basa en el uso de ReLu y softmax, pero para eso primero hay que explicar las partes basicas\n",
    "\n",
    "## Pesos\n",
    "Los coeficientes que se van ajustando durante el entrenamiento de la red neuronal,cada conexion tiene un peso que determina la importancia de su senal\n",
    "\n",
    "## Sesgo\n",
    "Termino adicional que se le agrega a la entrada de cada neurona para ajustar la salida de la funcino de activacion, se suele inciializar con ceros\n",
    "\n",
    "## ReLU\n",
    "Permite introducir no linealidad a la red\n",
    "ReLU(z) = max(0, z)\n",
    "\n",
    "## Softmax\n",
    "Convierte las salidas en probabilidades, esto permite clasificacion multiclase\n",
    "softmax(z_i) = exp(z_i) / sum(exp(z_j))\n",
    "\n",
    "## Forward pass\n",
    "Es la forma en la que la entrada se propaga a traves de la red a traves de todas las capaz hasta obteer la salida, en donde:\n",
    "\n",
    "### Capa de entrada oculta:\n",
    "Z1 =X⋅W 1​ +b 1\n",
    "​A1 = ReLU(Z1)\n",
    "\n",
    "### Capa oculta a capa de salida\n",
    "Z2 = A1 * W2 + b2\n",
    "A2 = softmax(Z2)\n",
    "\n",
    "## Backward pass\n",
    "Tiene el fin de calcular los pesos y sesgos para posteriormente ajustarlos e ir mejorando la precision del modelo\n",
    "\n",
    "### Cuando hay error en la capa de salida:\n",
    "dZ2 = A2 - Yone-hot\n",
    "dW2 = 1/m * (A_{1}^{t} * dZ2)\n",
    "dv2 = 1/m * sumatoria(dZ2)\n",
    "\n",
    "### Cuando hay error en la capa oculta:\n",
    "dA1 = dZ2 * W_{2}^{T}\n",
    "dZ1 = dA1 * ReLU'(Z1)\n",
    "dW1 = 1/m * (X^T * dZ1)\n",
    "db1 = 1/m * sumatoria(dZ2)\n",
    "\n",
    "## Actualizar los pesos y sesgos\n",
    "W1 = W1 - alpha * dW1\n",
    "b1 = b1 - alpha * db1\n",
    "W2 = W2 - alpha * dW2\n",
    "b2 = b2 - alpha * db2\n",
    "\n",
    "## Entrenamiento\n",
    "Recibe los datos de entradas, los resultados de y y los ephocs (Numero de veces que el modelo vera todo el conjunto de los datos), por cada vez que se ven los datos la red hace un forward pass para calcular las salidas de la red neuronal para las entradas dadas, lo que pasa las entradas a traves de las capaz de cada red aplicando sus funciones de activacion, posteriormente hace un backward pass en donde se calculan los pesos usando el error que hubo entre las predicciones y los valores reales, a partir de ello actualiza los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.01):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Inicializar pesos\n",
    "        self.W1 = np.random.randn(input_size, hidden_size) * 0.01\n",
    "        self.b1 = np.zeros((1, hidden_size))\n",
    "        self.W2 = np.random.randn(hidden_size, output_size) * 0.01\n",
    "        self.b2 = np.zeros((1, output_size))\n",
    "    \n",
    "    def relu(self, Z):\n",
    "        return np.maximum(0, Z)\n",
    "    \n",
    "    def relu_derivative(self, Z):\n",
    "        return Z > 0\n",
    "    \n",
    "    def softmax(self, Z):\n",
    "        exp_values = np.exp(Z - np.max(Z, axis=1, keepdims=True))\n",
    "        return exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # Capa de entrada a capa oculta\n",
    "        self.Z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.A1 = self.relu(self.Z1)\n",
    "        \n",
    "        # Capa oculta a capa de salida\n",
    "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
    "        self.A2 = self.softmax(self.Z2)\n",
    "        \n",
    "        return self.A2\n",
    "    \n",
    "    def backward(self, X, y, output):\n",
    "        # Convertir y a one-hot encoding\n",
    "        y_one_hot = np.zeros((y.size, self.output_size))\n",
    "        y_one_hot[np.arange(y.size), y] = 1\n",
    "        \n",
    "        # Error en la capa de salida\n",
    "        dZ2 = output - y_one_hot\n",
    "        dW2 = np.dot(self.A1.T, dZ2) / y.size\n",
    "        db2 = np.sum(dZ2, axis=0, keepdims=True) / y.size\n",
    "        \n",
    "        # Error en la capa oculta\n",
    "        dA1 = np.dot(dZ2, self.W2.T)\n",
    "        dZ1 = dA1 * self.relu_derivative(self.Z1)\n",
    "        dW1 = np.dot(X.T, dZ1) / y.size\n",
    "        db1 = np.sum(dZ1, axis=0, keepdims=True) / y.size\n",
    "        \n",
    "        # Actualizar pesos y sesgos\n",
    "        self.W1 -= self.learning_rate * dW1\n",
    "        self.b1 -= self.learning_rate * db1\n",
    "        self.W2 -= self.learning_rate * dW2\n",
    "        self.b2 -= self.learning_rate * db2\n",
    "    \n",
    "    def train(self, X, y, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            output = self.forward(X)\n",
    "            self.backward(X, y, output)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        output = self.forward(X)\n",
    "        return np.argmax(output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "input_size = x_train.shape[1]\n",
    "hidden_size = 30000\n",
    "output_size = len(np.unique(y))\n",
    "learning_rate = 0.01\n",
    "\n",
    "nn = NeuralNetwork(input_size, hidden_size, output_size, learning_rate)\n",
    "\n",
    "nn.train(x_train, y_train, 1000)\n",
    "\n",
    "y_pred = nn.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_drug(age, sex, bp, cholesterol, na_to_k_ratio):\n",
    "    input_data = pd.DataFrame({\n",
    "        \"Age\": [age],\n",
    "        \"Sex\": [sex],\n",
    "        \"BP\": [bp],\n",
    "        \"Cholesterol\": [cholesterol],\n",
    "        \"Na_to_K\": [na_to_k_ratio]\n",
    "    })\n",
    "    \n",
    "    for column in [\"Sex\", \"BP\", \"Cholesterol\"]:\n",
    "        le = label_encoders[column]\n",
    "        input_data[column] = le.transform(input_data[column])\n",
    "        \n",
    "    input_features = scaler.transform(input_data.values)\n",
    "    \n",
    "    prediction = nn.predict(input_features)\n",
    "    predicted_drug = label_encoders[\"Drug\"].inverse_transform(prediction)\n",
    "    \n",
    "    return predicted_drug[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted drug: drugA\n"
     ]
    }
   ],
   "source": [
    "new_patient_prediction = predict_drug(52, \"M\", \"HIGH\", \"HIGH\", 12)\n",
    "print(f\"Predicted drug: {new_patient_prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preprocessing.pkl']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(nn, 'neural_network_model.pkl')\n",
    "joblib.dump((label_encoders, scaler, x_test, y_test), 'preprocessing.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
